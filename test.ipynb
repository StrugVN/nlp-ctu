{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa75fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient\n",
    "import py_vncorenlp\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from math import log\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import re\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"nlp\"]\n",
    "\n",
    "article_collection = db[\"article\"]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbf6a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_collection = db[\"article_tf_idf\"]\n",
    "list_tf_idf = list(tf_idf_collection.find({}))\n",
    "\n",
    "\n",
    "rows = []\n",
    "for doc in list_tf_idf:\n",
    "    article_id = doc['articleId']\n",
    "    tf_idf = doc.get('tf_idf', {})\n",
    "    tf_idf['articleId'] = article_id\n",
    "    rows.append(tf_idf)\n",
    "\n",
    "df_tf_idf_full = pd.DataFrame(rows)\n",
    "\n",
    "df_tf_idf_full.set_index('articleId', inplace=True)\n",
    "df_tf_idf_full = df_tf_idf_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab066aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_collection = db[\"article\"]\n",
    "list_articles = list(article_collection.find({}))\n",
    "\n",
    "df_articles = pd.DataFrame(list_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9045aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tf_idf_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52d5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query(query, model, tokenizer, topn=5):\n",
    "    tokens = tokenizer.word_segment(query)[0].split(' ')\n",
    "    expanded_tokens = set(tokens)\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            similar_words = model.wv.most_similar(token, topn=topn)\n",
    "            for word, _ in similar_words:\n",
    "                expanded_tokens.add(word.replace('_', ' '))\n",
    "\n",
    "    return expanded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents_by_query(query, tf_idf, word_model, tokenizer,  stopwords):\n",
    "    # tokenize query\n",
    "    segmented = tokenizer.word_segment(query)\n",
    "    query_tokens = []\n",
    "    for sentence in segmented:\n",
    "        words = sentence.split()\n",
    "        words = [w.replace(\"_\", \" \") for w in words]\n",
    "        words = [w.lower() for w in words if w.lower() not in stopwords]\n",
    "        query_tokens.extend(words)\n",
    "\n",
    "    query_tokens_expanded = query_tokens.copy()\n",
    "\n",
    "    for token in query_tokens:\n",
    "        token_expand = expand_query(token, word_model, tokenizer, topn=5)\n",
    "        if token_expand:\n",
    "            for word in token_expand:\n",
    "                query_tokens_expanded.append(word)\n",
    "        \n",
    "\n",
    "    word_list = tf_idf.columns\n",
    "    query_vector = np.zeros(len(word_list))\n",
    "\n",
    "    word_counts = {word: query_tokens_expanded.count(word) for word in set(query_tokens_expanded)}\n",
    "\n",
    "    total_terms = sum(word_counts.values())\n",
    "    if total_terms == 0:\n",
    "        return []\n",
    "\n",
    "    for i, term in enumerate(word_list):\n",
    "        if term in word_counts:\n",
    "            query_vector[i] = word_counts[term] / total_terms \n",
    "\n",
    "    cosin_sim = cosine_similarity([query_vector], tf_idf.values)[0]\n",
    "\n",
    "    article_ids = tf_idf.index.tolist()\n",
    "    ranked = sorted(zip(article_ids, cosin_sim), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102a4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_vncorenlp\n",
    "import os\n",
    "original_cwd = os.getcwd()\n",
    "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir=os.path.join(original_cwd, \"vncorenlp\"))\n",
    "os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d08905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "py_vncorenlp.vncorenlp.VnCoreNLP"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdrsegmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e5a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip().lower() for line in f if line.strip())\n",
    "stopwords.add('sto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5513d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"word2vec_vi_baost.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97ace4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_articles(query):\n",
    "    results = rank_documents_by_query(query, df_tf_idf_full, word2vec_model, rdrsegmenter, stopwords)\n",
    "    result_ids = results[:10]\n",
    "    result_articles = list(article_collection.find({\"id\": {\"$in\": [item[0] for item in result_ids]}}))\n",
    "    return result_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cc712e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sẽ có đường hoa tại TP. Sóc Trăng dịp Tết năm 2018\n",
      "--------------------------------------------------------------------------------\n",
      "13 câu lạc bộ tham gia tranh tài\n",
      "--------------------------------------------------------------------------------\n",
      "Bưởi Da xanh Kế Sách\n",
      "--------------------------------------------------------------------------------\n",
      "Tổ chức giải Đua vỏ lãi nam năm 2024\n",
      "--------------------------------------------------------------------------------\n",
      "Huy động trên 1 tỷ đồng chăm lo cho nạn nhân chất độc da cam, người khuyết tật, người già\n",
      "--------------------------------------------------------------------------------\n",
      "Huyện Cù Lao Dung vững bước đón tân xuân\n",
      "--------------------------------------------------------------------------------\n",
      "Xã An Thạnh 1 nâng chất nông thôn mới nâng cao, tiến tới xây dựng nông thôn mới kiểu mẫu\n",
      "--------------------------------------------------------------------------------\n",
      "Bàn giao nhà tình thương cho hộ ông Mai Dôl\n",
      "--------------------------------------------------------------------------------\n",
      "Dâng hương tưởng niệm Chủ tịch Hồ Chí Minh\n",
      "--------------------------------------------------------------------------------\n",
      "Trung tâm Chính trị huyện Mỹ Xuyên học tập, làm theo Bác để nâng cao chất lượng đào tạo\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for article in search_articles('xe hơi'):\n",
    "    print(article['title'])\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2530b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vận động đồng bào Khmer chung sức xây dựng nông thôn mới nâng cao\n",
      "--------------------------------------------------------------------------------\n",
      "13 câu lạc bộ tham gia tranh tài\n",
      "--------------------------------------------------------------------------------\n",
      "Vận động, đoàn kết đồng bào tôn giáo tham gia các cuộc vận động, phong trào thi đua yêu nước ở địa phương\n",
      "--------------------------------------------------------------------------------\n",
      "Tổ chức giải Đua vỏ lãi nam năm 2024\n",
      "--------------------------------------------------------------------------------\n",
      "Hội cựu chiến binh các cấp luôn đi đầu trong phong trào bảo vệ an ninh Tổ quốc\n",
      "--------------------------------------------------------------------------------\n",
      "Huy động trên 1 tỷ đồng chăm lo cho nạn nhân chất độc da cam, người khuyết tật, người già\n",
      "--------------------------------------------------------------------------------\n",
      "Bàn giao nhà tình thương cho hộ ông Mai Dôl\n",
      "--------------------------------------------------------------------------------\n",
      "Dâng hương tưởng niệm Chủ tịch Hồ Chí Minh\n",
      "--------------------------------------------------------------------------------\n",
      "Trung tâm Chính trị huyện Mỹ Xuyên học tập, làm theo Bác để nâng cao chất lượng đào tạo\n",
      "--------------------------------------------------------------------------------\n",
      "Ngôi nhà thứ hai của học sinh dân tộc thiểu số\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for article in search_articles('xe du lịch'):\n",
    "    print(article['title'])\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3028ef5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStop\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "source": [
    "raise 'Stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225aa114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Từ: tai_nạn\n",
      "thương tích (điểm tương đồng: 0.794)\n",
      "kiềm chế (điểm tương đồng: 0.718)\n",
      "bệnh nghề nghiệp (điểm tương đồng: 0.701)\n",
      "TNGT (điểm tương đồng: 0.682)\n",
      "giao thông (điểm tương đồng: 0.68)\n",
      "--------------------------------------------------\n",
      "Từ: giao_thông\n",
      "ATGT (điểm tương đồng: 0.697)\n",
      "đường bộ (điểm tương đồng: 0.683)\n",
      "tai nạn (điểm tương đồng: 0.68)\n",
      "đường thuỷ (điểm tương đồng: 0.667)\n",
      "thông suốt (điểm tương đồng: 0.655)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_word = 'tai nạn giao thông'\n",
    "\n",
    "token_list = rdrsegmenter.word_segment(input_word)[0].split(' ')\n",
    "\n",
    "for input_tokenized in token_list:\n",
    "    print(f\"Từ: {input_tokenized}\")\n",
    "    if input_tokenized in word2vec_model.wv:\n",
    "        similar_words = word2vec_model.wv.most_similar(input_tokenized, topn=5)\n",
    "        for word, score in similar_words:\n",
    "            print(f\"{word.replace('_', ' ')} (điểm tương đồng: {round(score, 3)})\")\n",
    "    else:\n",
    "        print(\"Từ này không có trong từ điển đã huấn luyện.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c48224",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(\n",
    "    sentences=all_tokenized_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=1,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "word2vec_model.save(\"word2vec_vi_baost.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Từ: tai_nạn\n",
      "thương tích (điểm tương đồng: 0.794)\n",
      "kiềm chế (điểm tương đồng: 0.718)\n",
      "bệnh nghề nghiệp (điểm tương đồng: 0.701)\n",
      "TNGT (điểm tương đồng: 0.682)\n",
      "giao thông (điểm tương đồng: 0.68)\n",
      "--------------------------------------------------\n",
      "Từ: giao_thông\n",
      "ATGT (điểm tương đồng: 0.697)\n",
      "đường bộ (điểm tương đồng: 0.683)\n",
      "tai nạn (điểm tương đồng: 0.68)\n",
      "đường thuỷ (điểm tương đồng: 0.667)\n",
      "thông suốt (điểm tương đồng: 0.655)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d23c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection = db[\"article_df\"]\n",
    "list_df = list(df_collection.find({}))\n",
    "df_df = pd.DataFrame(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e4ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_df['articleId'].apply(lambda x : x.lower().strip()).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11b3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'thông suốt' in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bab474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29f59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TNGT',\n",
       " 'bệnh nghề nghiệp',\n",
       " 'giao thông',\n",
       " 'kiềm chế',\n",
       " 'tai_nạn',\n",
       " 'thương tích'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_query = expand_query('tai nạn', word2vec_model, topn=5)\n",
    "expanded_query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
