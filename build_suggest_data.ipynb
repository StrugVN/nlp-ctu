{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc9d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import kenlm\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def _sent_logp(lm, tokens):\n",
    "    # Score the sentence formed by joining tokens with spaces\n",
    "    # (log10; bos/eos disabled to match autocomplete style)\n",
    "    return lm.score(\" \".join(tokens), bos=False, eos=False)\n",
    "\n",
    "def _cond_logp(lm, history, nxt):\n",
    "    # log P(nxt | history) via sentence-score diff\n",
    "    return _sent_logp(lm, history + [nxt]) - _sent_logp(lm, history)\n",
    "\n",
    "def _topk_followers(lm, history, candidates, K):\n",
    "    # Return top-K (token, logp) for P(token | history)\n",
    "    heap = []\n",
    "    base = _sent_logp(lm, history)\n",
    "    for tok in candidates:\n",
    "        lp = _sent_logp(lm, history + [tok]) - base\n",
    "        if len(heap) < K:\n",
    "            heapq.heappush(heap, (lp, tok))\n",
    "        elif lp > heap[0][0]:\n",
    "            heapq.heapreplace(heap, (lp, tok))\n",
    "    return sorted(((tok, lp) for lp, tok in heap), key=lambda x: -x[1])\n",
    "\n",
    "def build_sequences(lm, w2v, K=5, V_LIMIT=50000, CAND_M=None, out_jsonl=\"seqs.jsonl\"):\n",
    "    \"\"\"\n",
    "    Build a flat JSONL of scored sequences (2/3/4 tokens) using KenLM for ranking.\n",
    "    Each line: {\"seq\": [\"A\",\"B\"], \"score\": ...} or length-3/4 analogs.\n",
    "\n",
    "    Args:\n",
    "      lm: kenlm.Model (already loaded)\n",
    "      w2v: gensim Word2Vec (already loaded)\n",
    "      K: beam width and per-step top-k\n",
    "      V_LIMIT: cap vocab size (Word2Vec frequency order)\n",
    "      CAND_M: if set, prefilter with w2v.most_similar(token, topn=CAND_M); fallback to full V if OOV\n",
    "      out_jsonl: output file path\n",
    "    \"\"\"\n",
    "    V = w2v.wv.index_to_key[:V_LIMIT]\n",
    "\n",
    "    def cand_for(tok):\n",
    "        if CAND_M is None or tok not in w2v.wv:\n",
    "            return V\n",
    "        return [w for (w, _) in w2v.wv.most_similar(tok, topn=min(CAND_M, len(V)))]\n",
    "\n",
    "    with open(out_jsonl, \"w\", encoding=\"utf-8\") as out:\n",
    "        for i, A in enumerate(V):\n",
    "            # ---- length 2: [A, B] ----\n",
    "            topB = _topk_followers(lm, [A], cand_for(A), K)  # [(B, lpB)]\n",
    "            for B, sAB in topB:\n",
    "                out.write(json.dumps({\"seq\": [A, B], \"score\": sAB}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            # ---- length 3: [A, B, C] (beam over B) ----\n",
    "            beam3 = []\n",
    "            for B, sAB in topB:\n",
    "                topC = _topk_followers(lm, [A, B], cand_for(B), K)  # [(C, lpC)]\n",
    "                for C, sC in topC:\n",
    "                    beam3.append((A, B, C, sAB + sC))\n",
    "            beam3.sort(key=lambda x: -x[3])\n",
    "            beam3 = beam3[:K]\n",
    "            for A_, B_, C_, sABC in beam3:\n",
    "                out.write(json.dumps({\"seq\": [A_, B_, C_], \"score\": sABC}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            # ---- length 4: [A, B, C, D] (beam over triples) ----\n",
    "            for A_, B_, C_, sABC in beam3:\n",
    "                topD = _topk_followers(lm, [A_, B_, C_], cand_for(C_), K)  # [(D, lpD)]\n",
    "                for D, sD in topD:\n",
    "                    out.write(json.dumps({\"seq\": [A_, B_, C_, D], \"score\": sABC + sD}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            if (i + 1) % 500 == 0:\n",
    "                print(f\"processed {i+1}/{len(V)} tokens\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83902d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenml = kenlm.Model(\"vi_model_6gramVinToken.binary\")\n",
    "w2v = Word2Vec.load(\"word2vec_vi_bao_st.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae402ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10755"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4faadd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 500/10755 tokens\n",
      "processed 1000/10755 tokens\n",
      "processed 1500/10755 tokens\n",
      "processed 2000/10755 tokens\n",
      "processed 2500/10755 tokens\n",
      "processed 3000/10755 tokens\n",
      "processed 3500/10755 tokens\n",
      "processed 4000/10755 tokens\n",
      "processed 4500/10755 tokens\n",
      "processed 5000/10755 tokens\n",
      "processed 5500/10755 tokens\n",
      "processed 6000/10755 tokens\n",
      "processed 6500/10755 tokens\n",
      "processed 7000/10755 tokens\n",
      "processed 7500/10755 tokens\n",
      "processed 8000/10755 tokens\n",
      "processed 8500/10755 tokens\n",
      "processed 9000/10755 tokens\n",
      "processed 9500/10755 tokens\n",
      "processed 10000/10755 tokens\n",
      "processed 10500/10755 tokens\n"
     ]
    }
   ],
   "source": [
    "build_sequences(kenml, w2v, K=5, V_LIMIT=50000, CAND_M=None, out_jsonl=\"suggestion.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e580d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(jsonl_path):\n",
    "    sequences = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                sequences.append(json.loads(line))\n",
    "    return sequences\n",
    "\n",
    "def find_by_prefix(sequences, prefix, topn=10):\n",
    "    plen = len(prefix)\n",
    "    matches = [rec for rec in sequences if rec[\"seq\"][:plen] == prefix]\n",
    "    matches.sort(key=lambda x: -x[\"score\"])\n",
    "    return matches[:topn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9cae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "seqs = load_sequences(\"suggestion.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1957511f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'seq': ['tai nạn', 'giao'], 'score': -0.3564491271972656},\n",
       " {'seq': ['tai nạn', 'giao thông'], 'score': -0.36070823669433594},\n",
       " {'seq': ['tai nạn', 'giao', 'thông'], 'score': -0.36070823669433594},\n",
       " {'seq': ['tai nạn', 'nhân'], 'score': -1.061161994934082},\n",
       " {'seq': ['tai nạn', 'lao'], 'score': -1.0780587196350098},\n",
       " {'seq': ['tai nạn', 'lao động'], 'score': -1.0887422561645508},\n",
       " {'seq': ['tai nạn', 'lao', 'động'], 'score': -1.0887422561645508},\n",
       " {'seq': ['tai nạn', 'nhân', 'chất'], 'score': -1.464848518371582},\n",
       " {'seq': ['tai nạn', 'nhân', 'chất độc'], 'score': -1.4769086837768555},\n",
       " {'seq': ['tai nạn', 'nhân', 'chất', 'độc'], 'score': -1.4769086837768555}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = find_by_prefix(seqs, [\"tai nạn\"])\n",
    "res1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
