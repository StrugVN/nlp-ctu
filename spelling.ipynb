{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1fc40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient\n",
    "import py_vncorenlp\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from math import log\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import re\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"nlp\"]\n",
    "\n",
    "article_collection = db[\"article\"]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf119a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection = db[\"article_df\"]\n",
    "list_df = pd.DataFrame(df_collection.find({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aa994af",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list_df['articleId'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3afd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return {l.strip() for l in f if l.strip()}\n",
    "\n",
    "def ngrams(s, n=2):\n",
    "    return {s[i:i+n] for i in range(len(s)-n+1)} if len(s)>=n else {s}\n",
    "\n",
    "def edit_dist(a, b):\n",
    "    if abs(len(a)-len(b))>1: return 2\n",
    "    dp = [[j if i==0 else (i if j==0 else 0)\n",
    "           for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    for i in range(1, len(a)+1):\n",
    "        for j in range(1, len(b)+1):\n",
    "            cost = 0 if a[i-1]==b[j-1] else 1\n",
    "            dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)\n",
    "    return dp[-1][-1]\n",
    "\n",
    "def spell_correcting(s, dict_path):\n",
    "    D = load_dict(dict_path)\n",
    "    tks = s.split()\n",
    "    s2 = ngrams(s)\n",
    "    return sorted(\n",
    "        e for e in D\n",
    "        if e.count(' ')==len(tks)-1\n",
    "           and edit_dist(s, e)==1\n",
    "           and (s2 & ngrams(e))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6770023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : ta nạn\n",
      "Corrected: ['tai nạn', 'tị nạn']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ta nạn\"\n",
    "fixed = spell_correcting(sentence, \"vietDict.txt\") \n",
    "print(\"Original :\", sentence)\n",
    "print(\"Corrected:\", fixed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d6cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64edd3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ta', 'nạn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b782181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_vncorenlp\n",
    "import os\n",
    "original_cwd = os.getcwd()\n",
    "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir=os.path.join(original_cwd, \"vncorenlp\"))\n",
    "os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974020d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip().lower() for line in f if line.strip())\n",
    "stopwords.add('sto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a00d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from query_processing import beam_search_kenlm, load_vocab_from_file, generate_progressive_suggestions\n",
    "import kenlm\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "kenMlModel = kenlm.Model(\"vi_model_6gramVinToken.binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b7de085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diễn biến con bảo số 10\n",
      "['diễn biến', 'con', 'bảo', 'số', '10']\n",
      "[['diễn tiến'], ['bon', 'co', 'coi', 'cong', 'gon', 'lon', 'non', 'son', 'đon'], ['bả', 'bản', 'bảy', 'cảo', 'hảo', 'rảo', 'sảo', 'tảo', 'xảo', 'đảo', 'ảo'], ['sốc', 'sốt'], []]\n"
     ]
    }
   ],
   "source": [
    "query = \"diễn biến cơn bão số 10\"\n",
    "beamResult = beam_search_kenlm(query.lower().split(), kenMlModel, force=True)\n",
    "add_tonal = detokenize(beamResult[0][0])\n",
    "print(add_tonal)\n",
    "\n",
    "segmented = rdrsegmenter.word_segment(add_tonal)\n",
    "query_tokens = []\n",
    "for sentence in segmented:\n",
    "    words = sentence.split()\n",
    "    words = [w.replace(\"_\", \" \") for w in words]\n",
    "    query_tokens.extend(words)\n",
    "print(query_tokens)\n",
    "\n",
    "query_tokens_corrected = []\n",
    "for word in query_tokens:\n",
    "    query_tokens_corrected.append(spell_correcting(word, \"vietDict.txt\"))\n",
    "\n",
    "print(query_tokens_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b5f4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_correcting('đua ghe ngo', \"vietDictNew.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6bd1ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vietDict.txt\", encoding='utf-8') as f_in:\n",
    "    current_words = set(f_in.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5933958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    current_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfd60e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vietDictNew.txt\", encoding='utf-8', mode='w+') as f_out:\n",
    "    f_out.write('\\n'.join(sorted(current_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68793bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23429"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cef3f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31462"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
